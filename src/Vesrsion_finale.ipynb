{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "import re\n",
        "import math\n",
        "import spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SmartSearchEngine:\n",
        "    def __init__(self, df):\n",
        "        self.df = df\n",
        "        self.inverted_index = defaultdict(lambda: defaultdict(list))\n",
        "        self.doc_lengths = {}\n",
        "        self.avg_doc_length = {}\n",
        "        self.N = len(df)\n",
        "        \n",
        "        # Load spaCy model with lemmatization\n",
        "        print(\"Loading spaCy model...\")\n",
        "        self.nlp = spacy.load(\"en_core_web_sm\")\n",
        "        \n",
        "        # Définir les champs à indexer\n",
        "        self.fields = ['Title', 'Director', 'Genres', 'Overview', 'Release_Date']\n",
        "        \n",
        "        # Créer des dictionnaires pour reconnaissance automatique\n",
        "        self.directors_set = set()\n",
        "        self.genres_set = set()\n",
        "        self.title_words = set()\n",
        "        self.years_set = set()\n",
        "        \n",
        "        self.build_index()\n",
        "        self.build_recognition_dicts()\n",
        "    \n",
        "    def preprocess_text(self, text, is_date=False):\n",
        "        \"\"\"Nettoyage et tokenisation avec spaCy + lemmatization\"\"\"\n",
        "        if pd.isna(text):\n",
        "            return []\n",
        "        text = str(text).lower()\n",
        "        \n",
        "        # Pour les dates, extraire l'année (format: YYYY-MM-DD ou juste YYYY)\n",
        "        if is_date:\n",
        "            year_match = re.findall(r'\\b(?:19|20)\\d{2}\\b', text)\n",
        "            return year_match if year_match else []\n",
        "        \n",
        "        # Process with spaCy\n",
        "        doc = self.nlp(text)\n",
        "        \n",
        "        # Extract lemmas with spaCy's built-in stopwords\n",
        "        tokens = [\n",
        "            token.lemma_ \n",
        "            for token in doc \n",
        "            if not token.is_stop          # spaCy's built-in stopwords (326 words)\n",
        "            and not token.is_punct        # Remove punctuation\n",
        "            and not token.is_space        # Remove whitespace\n",
        "            and len(token.lemma_) > 2     # Remove short tokens\n",
        "            and token.is_alpha            # Keep only alphabetic tokens\n",
        "        ]\n",
        "        \n",
        "        return tokens\n",
        "    \n",
        "    def build_index(self):\n",
        "        \"\"\"Construction de l'index inversé par champ\"\"\"\n",
        "        print(\"Construction de l'index inversé...\")\n",
        "        \n",
        "        for field in self.fields:\n",
        "            self.doc_lengths[field] = {}\n",
        "            self.avg_doc_length[field] = 0\n",
        "        \n",
        "        for idx, row in self.df.iterrows():\n",
        "            for field in self.fields:\n",
        "                # Traitement spécial pour les dates\n",
        "                is_date_field = (field == 'Release_Date')\n",
        "                tokens = self.preprocess_text(row[field], is_date=is_date_field)\n",
        "                self.doc_lengths[field][idx] = len(tokens)\n",
        "                \n",
        "                term_freq = defaultdict(int)\n",
        "                for token in tokens:\n",
        "                    term_freq[token] += 1\n",
        "                \n",
        "                for term, freq in term_freq.items():\n",
        "                    self.inverted_index[field][term].append((idx, freq))\n",
        "        \n",
        "        for field in self.fields:\n",
        "            if self.doc_lengths[field]:\n",
        "                self.avg_doc_length[field] = np.mean(list(self.doc_lengths[field].values()))\n",
        "        \n",
        "        print(f\"Index construit : {len(self.df)} documents indexés\")\n",
        "    \n",
        "    def build_recognition_dicts(self):\n",
        "        \"\"\"Construire des dictionnaires pour reconnaître automatiquement les termes\"\"\"\n",
        "        print(\"Construction des dictionnaires de reconnaissance...\")\n",
        "        \n",
        "        # Extraire tous les réalisateurs\n",
        "        for director in self.df['Director'].dropna().unique():\n",
        "            tokens = self.preprocess_text(director)\n",
        "            self.directors_set.update(tokens)\n",
        "        \n",
        "        # Extraire tous les genres\n",
        "        for genres in self.df['Genres'].dropna():\n",
        "            for genre in str(genres).split(','):\n",
        "                tokens = self.preprocess_text(genre.strip())\n",
        "                self.genres_set.update(tokens)\n",
        "        \n",
        "        # Extraire mots importants des titres\n",
        "        for title in self.df['Title'].dropna():\n",
        "            tokens = self.preprocess_text(title)\n",
        "            self.title_words.update(tokens)\n",
        "        \n",
        "        # Extraire toutes les années des dates de sortie\n",
        "        for date in self.df['Release_Date'].dropna():\n",
        "            years = self.preprocess_text(date, is_date=True)\n",
        "            self.years_set.update(years)\n",
        "        \n",
        "        print(f\"Réalisateurs uniques: {len(self.directors_set)}\")\n",
        "        print(f\"Genres uniques: {len(self.genres_set)}\")\n",
        "        print(f\"Années disponibles: {len(self.years_set)}\")\n",
        "    \n",
        "    def classify_query_terms(self, query_tokens):\n",
        "        \"\"\"Classifier automatiquement chaque terme de la requête\"\"\"\n",
        "        classified = {\n",
        "            'director': [],\n",
        "            'genre': [],\n",
        "            'title': [],\n",
        "            'year': [],\n",
        "            'general': []\n",
        "        }\n",
        "        \n",
        "        for term in query_tokens:\n",
        "            # Vérifier si c'est une année (4 chiffres commençant par 19 ou 20)\n",
        "            if re.match(r'^(?:19|20)\\d{2}$', term):\n",
        "                classified['year'].append(term)\n",
        "            # Vérifier dans quel champ le terme apparaît le plus\n",
        "            elif term in self.directors_set:\n",
        "                classified['director'].append(term)\n",
        "            elif term in self.genres_set:\n",
        "                classified['genre'].append(term)\n",
        "            elif term in self.title_words:\n",
        "                classified['title'].append(term)\n",
        "            else:\n",
        "                # Terme général, chercher partout\n",
        "                classified['general'].append(term)\n",
        "        \n",
        "        return classified\n",
        "    \n",
        "    def bm25_score(self, term, doc_id, field, k1=1.5, b=0.75):\n",
        "        \"\"\"Calcul du score BM25 pour un terme dans un document\"\"\"\n",
        "        if term not in self.inverted_index[field]:\n",
        "            return 0.0\n",
        "        \n",
        "        tf = 0\n",
        "        for doc, freq in self.inverted_index[field][term]:\n",
        "            if doc == doc_id:\n",
        "                tf = freq\n",
        "                break\n",
        "        \n",
        "        if tf == 0:\n",
        "            return 0.0\n",
        "        \n",
        "        df = len(self.inverted_index[field][term])\n",
        "        idf = math.log((self.N - df + 0.5) / (df + 0.5) + 1.0)\n",
        "        \n",
        "        doc_len = self.doc_lengths[field].get(doc_id, 0)\n",
        "        avg_len = self.avg_doc_length[field]\n",
        "        \n",
        "        if avg_len == 0:\n",
        "            return 0.0\n",
        "        \n",
        "        norm = 1 - b + b * (doc_len / avg_len)\n",
        "        score = idf * (tf * (k1 + 1)) / (tf + k1 * norm)\n",
        "        \n",
        "        return score\n",
        "    \n",
        "    def search(self, query, top_n=10):\n",
        "        \"\"\"Recherche intelligente avec classification automatique des termes\"\"\"\n",
        "        # Extraire les années AVANT le preprocessing\n",
        "        years_in_query = re.findall(r'\\b(?:19|20)\\d{2}\\b', query)\n",
        "        \n",
        "        # Tokeniser la requête avec spaCy + lemmatization\n",
        "        query_tokens = self.preprocess_text(query)\n",
        "        \n",
        "        # Ajouter les années extraites aux tokens\n",
        "        query_tokens.extend(years_in_query)\n",
        "        \n",
        "        if not query_tokens:\n",
        "            return pd.DataFrame()\n",
        "        \n",
        "        # Classifier les termes de la requête\n",
        "        classified = self.classify_query_terms(query_tokens)\n",
        "        \n",
        "        # Debug: afficher la classification\n",
        "        print(f\"\\n=== Classification des termes ===\")\n",
        "        for category, terms in classified.items():\n",
        "            if terms:\n",
        "                print(f\"{category.capitalize()}: {terms}\")\n",
        "        \n",
        "        # Collecter tous les documents candidats\n",
        "        candidate_docs = set()\n",
        "        \n",
        "        # Chercher les termes dans leurs champs correspondants\n",
        "        field_mapping = {\n",
        "            'director': ['Director'],\n",
        "            'genre': ['Genres'],\n",
        "            'title': ['Title'],\n",
        "            'year': ['Release_Date'],\n",
        "            'general': ['Title', 'Director', 'Genres', 'Overview']\n",
        "        }\n",
        "        \n",
        "        for category, terms in classified.items():\n",
        "            target_fields = field_mapping[category]\n",
        "            for term in terms:\n",
        "                for field in target_fields:\n",
        "                    if term in self.inverted_index[field]:\n",
        "                        for doc_id, _ in self.inverted_index[field][term]:\n",
        "                            candidate_docs.add(doc_id)\n",
        "        \n",
        "        # Calculer les scores pour chaque document\n",
        "        scores = {}\n",
        "        for doc_id in candidate_docs:\n",
        "            total_score = 0.0\n",
        "            \n",
        "            # Score pour les termes de réalisateur\n",
        "            for term in classified['director']:\n",
        "                score = self.bm25_score(term, doc_id, 'Director')\n",
        "                total_score += score * 1.0\n",
        "            \n",
        "            # Score pour les termes de genre\n",
        "            for term in classified['genre']:\n",
        "                score = self.bm25_score(term, doc_id, 'Genres')\n",
        "                total_score += score * 1.0\n",
        "            \n",
        "            # Score pour les termes de titre\n",
        "            for term in classified['title']:\n",
        "                score = self.bm25_score(term, doc_id, 'Title')\n",
        "                total_score += score * 1.0\n",
        "            \n",
        "            # Score pour les années\n",
        "            for term in classified['year']:\n",
        "                score = self.bm25_score(term, doc_id, 'Release_Date')\n",
        "                total_score += score * 1.0\n",
        "            \n",
        "            # Score pour les termes généraux\n",
        "            for term in classified['general']:\n",
        "                for field in ['Title', 'Director', 'Genres', 'Overview', 'Release_Date']:\n",
        "                    score = self.bm25_score(term, doc_id, field)\n",
        "                    total_score += score * 1.0\n",
        "            \n",
        "            scores[doc_id] = total_score\n",
        "        \n",
        "        # Trier par score décroissant\n",
        "        sorted_docs = sorted(scores.items(), key=lambda x: x[1], reverse=True)[:top_n]\n",
        "        \n",
        "        if not sorted_docs:\n",
        "            return pd.DataFrame()\n",
        "        \n",
        "        result_indices = [doc_id for doc_id, _ in sorted_docs]\n",
        "        result_scores = [score for _, score in sorted_docs]\n",
        "        \n",
        "        results = self.df.loc[result_indices, ['Title', 'Overview', 'Genres', 'Director', 'Release_Date']].copy()\n",
        "        results['score'] = result_scores\n",
        "        \n",
        "        return results.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset chargé : 4771 films\n",
            "Colonnes disponibles : ['Title', 'Overview', 'Tagline', 'Homepage', 'Release_Date', 'Vote_Average', 'Runtime', 'Poster_Path', 'Genres', 'Keywords', 'Director', 'budget', 'revenue', 'production_companies', 'Cast']\n",
            "\n",
            "Loading spaCy model...\n",
            "Construction de l'index inversé...\n",
            "Index construit : 4771 documents indexés\n",
            "Construction des dictionnaires de reconnaissance...\n",
            "Réalisateurs uniques: 2840\n",
            "Genres uniques: 21\n",
            "Années disponibles: 92\n"
          ]
        }
      ],
      "source": [
        "# ============ UTILISATION AVEC VRAIES DONNÉES ============\n",
        "\n",
        "# Charger les données\n",
        "df = pd.read_csv(\"../data/cleaned_movies.csv\")\n",
        "\n",
        "print(f\"Dataset chargé : {len(df)} films\")\n",
        "print(f\"Colonnes disponibles : {df.columns.tolist()}\\n\")\n",
        "\n",
        "# Créer le moteur de recherche\n",
        "engine = SmartSearchEngine(df)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Classification des termes ===\n",
            "Director: ['christopher', 'nolan']\n",
            "Genre: ['action', 'movie']\n",
            "Year: ['2010']\n",
            "                                Title               Director  \\\n",
            "0                           Inception      Christopher Nolan   \n",
            "1                       Batman Begins      Christopher Nolan   \n",
            "2                     The Dark Knight      Christopher Nolan   \n",
            "3               The Dark Knight Rises      Christopher Nolan   \n",
            "4                        Interstellar      Christopher Nolan   \n",
            "5                        The Prestige      Christopher Nolan   \n",
            "6                             Memento      Christopher Nolan   \n",
            "7                            Insomnia      Christopher Nolan   \n",
            "8                      Christmas Mail         John Murlowski   \n",
            "9  Mission: Impossible - Rogue Nation  Christopher McQuarrie   \n",
            "\n",
            "                               Genres Release_Date      score  \n",
            "0  Action, Science Fiction, Adventure   2010-07-15  15.756930  \n",
            "1                Action, Crime, Drama   2005-06-10  12.911074  \n",
            "2      Drama, Action, Crime, Thriller   2008-07-16  12.722313  \n",
            "3      Action, Crime, Drama, Thriller   2012-07-17  12.722313  \n",
            "4   Adventure, Drama, Science Fiction   2014-11-05  11.538807  \n",
            "5     Drama, Mystery, Science Fiction   2006-10-19  11.538807  \n",
            "6                   Mystery, Thriller   2000-10-11  11.538807  \n",
            "7                     Thriller, Crime   2002-05-24  11.538807  \n",
            "8            Comedy, Family, TV Movie   2010-12-04   8.750636  \n",
            "9                   Action, Adventure   2015-07-23   6.792516  \n"
          ]
        }
      ],
      "source": [
        "# ============ TESTS ============\n",
        "results = engine.search(\"action movies of christopher nolan 2010\", top_n=10)\n",
        "print(results[['Title' , 'Director','Genres', 'Release_Date', 'score']])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading spaCy model...\n",
            "Construction de l'index inversé...\n",
            "Index construit : 4771 documents indexés\n",
            "Construction des dictionnaires de reconnaissance...\n",
            "Réalisateurs uniques: 2840\n",
            "Genres uniques: 21\n",
            "Années disponibles: 92\n",
            "\n",
            "=== Classification des termes ===\n",
            "Director: ['tarantino']\n",
            "Genre: ['action']\n",
            "\n",
            "=== Classification des termes ===\n",
            "Director: ['nolan']\n",
            "Year: ['2010']\n",
            "\n",
            "=== Classification des termes ===\n",
            "Director: ['spielberg']\n",
            "Genre: ['adventure']\n",
            "\n",
            "=== Classification des termes ===\n",
            "Genre: ['horror']\n",
            "Year: ['2019']\n",
            "\n",
            "=== Classification des termes ===\n",
            "Genre: ['animation']\n",
            "\n",
            "=== Classification des termes ===\n",
            "Director: ['scorsese']\n",
            "Genre: ['crime']\n",
            "\n",
            "=== Classification des termes ===\n",
            "Genre: ['war']\n",
            "Title: ['star']\n",
            "\n",
            "=== Classification des termes ===\n",
            "Title: ['batman']\n",
            "\n",
            "=== Classification des termes ===\n",
            "Genre: ['comedy']\n",
            "Year: ['2015']\n",
            "\n",
            "=== Classification des termes ===\n",
            "General: ['pixar']\n",
            "\n",
            "============================================================\n",
            "RÉSULTATS DE L'ÉVALUATION\n",
            "============================================================\n",
            "Accuracy:  100.00%\n",
            "Precision: 100.00%\n",
            "Recall:    100.00%\n",
            "F1-Score:  100.00%\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "\n",
        "class SearchEngineEvaluator:\n",
        "    \"\"\"\n",
        "    Évaluation simple du moteur de recherche\n",
        "    Retourne juste les scores finaux\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, search_engine, df):\n",
        "        self.engine = search_engine\n",
        "        self.df = df\n",
        "    \n",
        "    def create_evaluation_dataset(self, test_queries):\n",
        "        \"\"\"Créer le dataset d'évaluation\"\"\"\n",
        "        all_results = []\n",
        "        \n",
        "        for query_info in test_queries:\n",
        "            query = query_info['query']\n",
        "            relevant_docs = set(query_info['relevant_docs'])\n",
        "            \n",
        "            results = self.engine.search(query, top_n=10)\n",
        "            \n",
        "            if results.empty:\n",
        "                continue\n",
        "            \n",
        "            for idx in results.index:\n",
        "                row = results.loc[idx]\n",
        "                all_results.append({\n",
        "                    'query': query,\n",
        "                    'doc_id': idx,\n",
        "                    'score': row['score'],\n",
        "                    'y_true': 1 if idx in relevant_docs else 0\n",
        "                })\n",
        "        \n",
        "        return pd.DataFrame(all_results)\n",
        "    \n",
        "    def find_best_threshold(self, eval_df):\n",
        "        \"\"\"Trouver le meilleur seuil pour maximiser F1\"\"\"\n",
        "        scores = eval_df['score'].values\n",
        "        thresholds = np.linspace(scores.min(), scores.max(), 10)\n",
        "        \n",
        "        best_f1 = 0\n",
        "        best_threshold = 0\n",
        "        \n",
        "        for threshold in thresholds:\n",
        "            y_pred = (eval_df['score'] >= threshold).astype(int)\n",
        "            f1 = f1_score(eval_df['y_true'], y_pred, zero_division=0)\n",
        "            \n",
        "            if f1 > best_f1:\n",
        "                best_f1 = f1\n",
        "                best_threshold = threshold\n",
        "        \n",
        "        return best_threshold\n",
        "    \n",
        "    def evaluate(self, test_queries):\n",
        "        \"\"\"\n",
        "        Évaluation complète - Retourne juste les scores\n",
        "        \n",
        "        Returns:\n",
        "            dict: {'accuracy': 0.95, 'precision': 0.92, 'recall': 0.88, 'f1_score': 0.90}\n",
        "        \"\"\"\n",
        "        # Créer le dataset\n",
        "        eval_df = self.create_evaluation_dataset(test_queries)\n",
        "        \n",
        "        if eval_df.empty:\n",
        "            return {\n",
        "                'accuracy': 0.0,\n",
        "                'precision': 0.0,\n",
        "                'recall': 0.0,\n",
        "                'f1_score': 0.0,\n",
        "                'error': 'Aucun résultat trouvé'\n",
        "            }\n",
        "        \n",
        "        # Trouver le meilleur seuil\n",
        "        best_threshold = self.find_best_threshold(eval_df)\n",
        "        \n",
        "        # Prédictions avec le meilleur seuil\n",
        "        eval_df['y_pred'] = (eval_df['score'] >= best_threshold).astype(int)\n",
        "        \n",
        "        y_true = eval_df['y_true'].values\n",
        "        y_pred = eval_df['y_pred'].values\n",
        "        \n",
        "        # Calculer les métriques\n",
        "        metrics = {\n",
        "            'accuracy': accuracy_score(y_true, y_pred),\n",
        "            'precision': precision_score(y_true, y_pred, zero_division=0),\n",
        "            'recall': recall_score(y_true, y_pred, zero_division=0),\n",
        "            'f1_score': f1_score(y_true, y_pred, zero_division=0),\n",
        "            'threshold': best_threshold\n",
        "        }\n",
        "        \n",
        "        return metrics\n",
        "\n",
        "\n",
        "# ============ HELPER POUR TROUVER LES DOCS PERTINENTS ============\n",
        "\n",
        "def find_relevant_docs(df, **criteria):\n",
        "    \"\"\"Trouve les documents pertinents selon des critères\"\"\"\n",
        "    mask = pd.Series([True] * len(df), index=df.index)\n",
        "    \n",
        "    if 'title' in criteria:\n",
        "        mask &= df['Title'].str.contains(criteria['title'], case=False, na=False)\n",
        "    if 'director' in criteria:\n",
        "        mask &= df['Director'].str.contains(criteria['director'], case=False, na=False)\n",
        "    if 'genre' in criteria:\n",
        "        mask &= df['Genres'].str.contains(criteria['genre'], case=False, na=False)\n",
        "    if 'year' in criteria:\n",
        "        mask &= df['Release_Date'].str.contains(str(criteria['year']), na=False)\n",
        "    \n",
        "    return df[mask].index.tolist()\n",
        "\n",
        "\n",
        "# ============ EXEMPLE D'UTILISATION ============\n",
        "\n",
        "# 1. Charger les données\n",
        "df = pd.read_csv(\"../data/cleaned_movies.csv\")\n",
        "engine = SmartSearchEngine(df)\n",
        "\n",
        "# 2. Créer les requêtes de test\n",
        "test_queries = [\n",
        "    {\n",
        "        'query': 'tarantino action',\n",
        "        'relevant_docs': find_relevant_docs(df, director='tarantino', genre='action')\n",
        "    },\n",
        "    {\n",
        "        'query': 'nolan 2010',\n",
        "        'relevant_docs': find_relevant_docs(df, director='nolan', year=2010)\n",
        "    },\n",
        "    {\n",
        "        'query': 'spielberg adventure',\n",
        "        'relevant_docs': find_relevant_docs(df, director='spielberg', genre='adventure')\n",
        "    },\n",
        "    {\n",
        "        'query': 'horror 2019',\n",
        "        'relevant_docs': find_relevant_docs(df, genre='horror', year=2019)\n",
        "    },\n",
        "    {\n",
        "        'query': 'animation',\n",
        "        'relevant_docs': find_relevant_docs(df, genre='animation')[:20]\n",
        "    },\n",
        "    {\n",
        "        'query': 'scorsese crime',\n",
        "        'relevant_docs': find_relevant_docs(df, director='scorsese', genre='crime')\n",
        "    },\n",
        "    {\n",
        "        'query': 'star wars',\n",
        "        'relevant_docs': find_relevant_docs(df, title='star wars')\n",
        "    },\n",
        "    {\n",
        "        'query': 'batman',\n",
        "        'relevant_docs': find_relevant_docs(df, title='batman')\n",
        "    },\n",
        "    {\n",
        "        'query': 'comedy 2015',\n",
        "        'relevant_docs': find_relevant_docs(df, genre='comedy', year=2015)\n",
        "    },\n",
        "    {\n",
        "        'query': 'pixar',\n",
        "        'relevant_docs': find_relevant_docs(df, title='pixar')[:15]\n",
        "    }\n",
        "]\n",
        "\n",
        "# 3. Évaluer et afficher les scores\n",
        "evaluator = SearchEngineEvaluator(engine, df)\n",
        "scores = evaluator.evaluate(test_queries)\n",
        "\n",
        "# 4. Afficher les résultats\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"RÉSULTATS DE L'ÉVALUATION\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Accuracy:  {scores['accuracy']*100:.2f}%\")\n",
        "print(f\"Precision: {scores['precision']*100:.2f}%\")\n",
        "print(f\"Recall:    {scores['recall']*100:.2f}%\")\n",
        "print(f\"F1-Score:  {scores['f1_score']*100:.2f}%\")\n",
        "print(\"=\"*60)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
