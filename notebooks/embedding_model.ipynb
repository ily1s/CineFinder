{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading JSONs: 100%|██████████| 3500/3500 [00:00<00:00, 13360.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3500 movies\n",
      "Generating embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 110/110 [00:09<00:00, 11.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index ready with 3500 movies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error in faiss::FileIOWriter::FileIOWriter(const char *) at /Users/runner/work/faiss-wheels/faiss-wheels/faiss/faiss/impl/io.cpp:102: Error: 'f' failed: could not open data/movie_index.faiss for writing: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[32m/var/folders/zq/0q87_f7x4hv8pv6xyzqx4bl00000gn/T/ipykernel_89689/2091718832.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     74\u001b[39m \n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n\u001b[32m     76\u001b[39m \u001b[38;5;66;03m# 5. Save everything\u001b[39;00m\n\u001b[32m     77\u001b[39m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m faiss.write_index(index, INDEX_FILE)\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m open(METADATA_FILE, \u001b[33m\"wb\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     80\u001b[39m     pickle.dump({\n\u001b[32m     81\u001b[39m         \u001b[33m\"movies\"\u001b[39m: movies,\n",
      "\u001b[32m~/Downloads/anaconda3/envs/cf/lib/python3.13/site-packages/faiss/swigfaiss.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args)\u001b[39m\n\u001b[32m  11634\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m write_index(*args):\n\u001b[32m> \u001b[39m\u001b[32m11635\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _swigfaiss.write_index(*args)\n",
      "\u001b[31mRuntimeError\u001b[39m: Error in faiss::FileIOWriter::FileIOWriter(const char *) at /Users/runner/work/faiss-wheels/faiss-wheels/faiss/faiss/impl/io.cpp:102: Error: 'f' failed: could not open data/movie_index.faiss for writing: No such file or directory"
     ]
    }
   ],
   "source": [
    "# 1. Install once\n",
    "# pip install sentence-transformers faiss-cpu tqdm\n",
    "# (use faiss-gpu if you have a good GPU)\n",
    "\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "import numpy as np\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "# -----------------------------\n",
    "# CONFIGURATION\n",
    "# -----------------------------\n",
    "FOLDER = \"../data/Docs\"           # ← your folder with .json files\n",
    "INDEX_FILE = \"data/movie_index.faiss\"\n",
    "METADATA_FILE = \"data/movie_metadata.pkl\"\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Load all movies\n",
    "# -----------------------------\n",
    "def load_movies():\n",
    "    files = glob.glob(os.path.join(FOLDER, \"*.json\"))\n",
    "    movies = []\n",
    "    for f in tqdm(files, desc=\"Loading JSONs\"):\n",
    "        with open(f, \"r\", encoding=\"utf8\") as jf:\n",
    "            data = json.load(jf)\n",
    "            movies.append(data)\n",
    "    return movies, files\n",
    "\n",
    "movies, file_paths = load_movies()\n",
    "print(f\"Loaded {len(movies)} movies\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Create clean searchable text\n",
    "# -----------------------------\n",
    "def make_text(movie):\n",
    "    parts = [\n",
    "        movie.get(\"Title\", \"\"),\n",
    "        movie.get(\"Overview\", \"\"),\n",
    "        movie.get(\"Tagline\", \"\"),\n",
    "        movie.get(\"Director\", \"\"),\n",
    "        movie.get(\"Cast\", \"\"),\n",
    "        movie.get(\"Genres\", \"\"),\n",
    "        str(movie.get(\"Release_Date\", \"\")[:4])\n",
    "    ]\n",
    "    return \" | \".join([p.strip() for p in parts if p])\n",
    "\n",
    "texts = [make_text(m) for m in movies]\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Load embedding model (small & fast or big & accurate)\n",
    "# -----------------------------\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")        # Super fast (5-10k movies in <10 sec)\n",
    "# model = SentenceTransformer(\"all-mpnet-base-v2\")     # More accurate (slower)\n",
    "# model = SentenceTransformer(\"BAAI/bge-small-en-v1.5\") # Best speed/quality 2025\n",
    "\n",
    "print(\"Generating embeddings...\")\n",
    "embeddings = model.encode(texts, batch_size=32, show_progress_bar=True)\n",
    "embeddings = np.array(embeddings).astype('float32')\n",
    "\n",
    "# Normalize for cosine similarity\n",
    "faiss.normalize_L2(embeddings)\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Build FAISS index\n",
    "# -----------------------------\n",
    "dimension = embeddings.shape[1]\n",
    "index = faiss.IndexFlatIP(dimension)   # Inner Product = cosine after normalization\n",
    "index.add(embeddings)\n",
    "print(f\"FAISS index ready with {index.ntotal} movies\")\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Save everything\n",
    "# -----------------------------\n",
    "faiss.write_index(index, INDEX_FILE)\n",
    "with open(METADATA_FILE, \"wb\") as f:\n",
    "    pickle.dump({\n",
    "        \"movies\": movies,\n",
    "        \"file_paths\": file_paths,\n",
    "        \"texts\": texts\n",
    "    }, f)\n",
    "\n",
    "print(\"Index saved! Ready for search.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
