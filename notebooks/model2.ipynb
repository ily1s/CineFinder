{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import math\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import spacy\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour charger tous les JSON d’un dossier\n",
    "def load_movies_from_json_folder(folder_path):\n",
    "    json_pattern = os.path.join(folder_path, \"*.json\")\n",
    "    json_files = glob.glob(json_pattern)\n",
    "    \n",
    "    if not json_files:\n",
    "        raise ValueError(f\"Aucun fichier .json trouvé dans {folder_path}\")\n",
    "    \n",
    "    print(f\"{len(json_files)} fichiers JSON trouvés. Chargement en cours...\")\n",
    "    \n",
    "    records = []\n",
    "    for file_path in json_files:\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "            records.append(data)\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur avec {file_path} : {e}\")\n",
    "    \n",
    "    df = pd.DataFrame(records)\n",
    "    \n",
    "    # Colonnes obligatoires (on crée les manquantes vides)\n",
    "    required = ['Title', 'Director', 'Genres', 'Overview', 'Release_Date']\n",
    "    for col in required:\n",
    "        if col not in df.columns:\n",
    "            df[col] = \"\"\n",
    "    \n",
    "    # Créer un ID stable (très utile quand on recharge)\n",
    "    if 'id' not in df.columns:\n",
    "        df = df.reset_index(drop=True)\n",
    "        df['id'] = df.index\n",
    "    \n",
    "    df = df.set_index('id')\n",
    "    \n",
    "    print(f\"Chargement terminé : {len(df)} films chargés\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmartSearchEngine:\n",
    "    def __init__(self, df, load_from_file=None):\n",
    "        self.df = df.copy()\n",
    "        self.N = len(df)\n",
    "        \n",
    "        print(\"Chargement du modèle spaCy...\")\n",
    "        self.nlp = spacy.load(\"en_core_web_sm\")\n",
    "        \n",
    "        self.fields = ['Title', 'Director', 'Genres', 'Overview', 'Release_Date']\n",
    "        \n",
    "        if load_from_file:\n",
    "            self.load_index(load_from_file)\n",
    "        else:\n",
    "            self.inverted_index = defaultdict(lambda: defaultdict(list))\n",
    "            self.doc_lengths = {}\n",
    "            self.avg_doc_length = {}\n",
    "            self.directors_set = set()\n",
    "            self.genres_set = set()\n",
    "            self.title_words = set()\n",
    "            self.years_set = set()\n",
    "            \n",
    "            self.build_index()\n",
    "            self.build_recognition_dicts()\n",
    "    \n",
    "    # -------------------------------------------------\n",
    "    def preprocess_text(self, text, is_date=False):\n",
    "        if pd.isna(text):\n",
    "            return []\n",
    "        text = str(text).lower()\n",
    "        if is_date:\n",
    "            return re.findall(r'\\b(?:19|20)\\d{2}\\b', text)\n",
    "        doc = self.nlp(text)\n",
    "        return [token.lemma_ for token in doc\n",
    "                if not token.is_stop and not token.is_punct and not token.is_space\n",
    "                and len(token.lemma_) > 2 and token.is_alpha]\n",
    "    \n",
    "    # -------------------------------------------------\n",
    "    def build_index(self):\n",
    "        print(\"Construction de l'index inversé...\")\n",
    "        for field in self.fields:\n",
    "            self.doc_lengths[field] = {}\n",
    "            self.avg_doc_length[field] = 0\n",
    "        \n",
    "        for idx, row in self.df.iterrows():\n",
    "            for field in self.fields:\n",
    "                tokens = self.preprocess_text(row[field], is_date=(field == 'Release_Date'))\n",
    "                self.doc_lengths[field][idx] = len(tokens)\n",
    "                freqs = defaultdict(int)\n",
    "                for t in tokens:\n",
    "                    freqs[t] += 1\n",
    "                for term, freq in freqs.items():\n",
    "                    self.inverted_index[field][term].append((idx, freq))\n",
    "        \n",
    "        for field in self.fields:\n",
    "            lengths = self.doc_lengths[field].values()\n",
    "            if lengths:\n",
    "                self.avg_doc_length[field] = np.mean(list(lengths))\n",
    "        \n",
    "        print(f\"Index construit : {self.N} documents\")\n",
    "    \n",
    "    # -------------------------------------------------\n",
    "    def build_recognition_dicts(self):\n",
    "        print(\"Construction des dictionnaires de reconnaissance...\")\n",
    "        for director in self.df['Director'].dropna():\n",
    "            self.directors_set.update(self.preprocess_text(director))\n",
    "        for genres in self.df['Genres'].dropna():\n",
    "            for g in str(genres).split(','):\n",
    "                self.genres_set.update(self.preprocess_text(g.strip()))\n",
    "        for title in self.df['Title'].dropna():\n",
    "            self.title_words.update(self.preprocess_text(title))\n",
    "        for date in self.df['Release_Date'].dropna():\n",
    "            self.years_set.update(self.preprocess_text(date, is_date=True))\n",
    "    \n",
    "    # -------------------------------------------------\n",
    "    def classify_query_terms(self, query_tokens):\n",
    "        classified = {'director':[], 'genre':[], 'title':[], 'year':[], 'general':[]}\n",
    "        for term in query_tokens:\n",
    "            if re.match(r'^(?:19|20)\\d{2}$', term):\n",
    "                classified['year'].append(term)\n",
    "            elif term in self.directors_set:\n",
    "                classified['director'].append(term)\n",
    "            elif term in self.genres_set:\n",
    "                classified['genre'].append(term)\n",
    "            elif term in self.title_words:\n",
    "                classified['title'].append(term)\n",
    "            else:\n",
    "                classified['general'].append(term)\n",
    "        return classified\n",
    "    \n",
    "    # -------------------------------------------------\n",
    "    def bm25_score(self, term, doc_id, field, k1=1.5, b=0.75):\n",
    "        if term not in self.inverted_index[field]:\n",
    "            return 0.0\n",
    "        postings = self.inverted_index[field][term]\n",
    "        tf = next((f for d, f in postings if d == doc_id), 0)\n",
    "        if tf == 0:\n",
    "            return 0.0\n",
    "        dfreq = len(postings)\n",
    "        idf = math.log((self.N - dfreq + 0.5) / (dfreq + 0.5) + 1.0)\n",
    "        doc_len = self.doc_lengths[field].get(doc_id, 0)\n",
    "        avg_len = self.avg_doc_length.get(field, 1) or 1\n",
    "        norm = 1 - b + b * (doc_len / avg_len)\n",
    "        return idf * (tf * (k1 + 1)) / (tf + k1 * norm)\n",
    "    \n",
    "    # -------------------------------------------------\n",
    "    def search(self, query, top_n=10):\n",
    "        years = re.findall(r'\\b(?:19|20)\\d{2}\\b', query)\n",
    "        tokens = self.preprocess_text(query) + years\n",
    "        if not tokens:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        classified = self.classify_query_terms(tokens)\n",
    "        print(\"\\n=== Classification ===\")\n",
    "        for cat, terms in classified.items():\n",
    "            if terms: print(f\"{cat.capitalize():8}: {terms}\")\n",
    "        \n",
    "        candidates = set()\n",
    "        mapping = {\n",
    "            'director': ['Director'],\n",
    "            'genre':    ['Genres'],\n",
    "            'title':    ['Title'],\n",
    "            'year':     ['Release_Date'],\n",
    "            'general':  self.fields\n",
    "        }\n",
    "        for cat, terms in classified.items():\n",
    "            for term in terms:\n",
    "                for field in mapping[cat]:\n",
    "                    if term in self.inverted_index[field]:\n",
    "                        candidates.update(d for d, _ in self.inverted_index[field][term])\n",
    "        \n",
    "        scores = {}\n",
    "        for doc_id in candidates:\n",
    "            s = 0.0\n",
    "            for t in classified['director']: s += self.bm25_score(t, doc_id, 'Director')\n",
    "            for t in classified['genre']:    s += self.bm25_score(t, doc_id, 'Genres')\n",
    "            for t in classified['title']:    s += self.bm25_score(t, doc_id, 'Title')\n",
    "            for t in classified['year']:     s += self.bm25_score(t, doc_id, 'Release_Date')\n",
    "            for t in classified['general']:\n",
    "                for f in self.fields:\n",
    "                    s += self.bm25_score(t, doc_id, f)\n",
    "            if s > 0:\n",
    "                scores[doc_id] = s\n",
    "        \n",
    "        top = sorted(scores.items(), key=lambda x: x[1], reverse=True)[:top_n]\n",
    "        if not top:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        ids, sc = zip(*top)\n",
    "        res = self.df.loc[list(ids), ['Title','Overview','Genres','Director','Release_Date']].copy()\n",
    "        res['score'] = sc\n",
    "        return res.reset_index(drop=True)\n",
    "    \n",
    "    # -------------------------------------------------\n",
    "    def save_index(self, folder_path=\"../data/index_data\"):\n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "        print(f\"Sauvegarde de l'index dans {folder_path}...\")\n",
    "        \n",
    "        # Correction ici : on utilise bien \"terms\" et pas \"terms_dict\"\n",
    "        serializable_index = {}\n",
    "        for field, terms in self.inverted_index.items():\n",
    "            serializable_index[field] = {}\n",
    "            for term, postings in terms.items():\n",
    "                serializable_index[field][term] = [[int(d), int(f)] for d, f in postings]\n",
    "        \n",
    "        with open(os.path.join(folder_path, \"inverted_index.json\"), 'w', encoding='utf-8') as f:\n",
    "            json.dump(serializable_index, f, ensure_ascii=False)\n",
    "        \n",
    "        metadata = {\n",
    "            'N': self.N,\n",
    "            'doc_lengths': {f: {int(k): v for k, v in d.items()} for f, d in self.doc_lengths.items()},\n",
    "            'avg_doc_length': self.avg_doc_length,\n",
    "            'directors_set': list(self.directors_set),\n",
    "            'genres_set': list(self.genres_set),\n",
    "            'title_words': list(self.title_words),\n",
    "            'years_set': list(self.years_set),\n",
    "            'fields': self.fields\n",
    "        }\n",
    "        with open(os.path.join(folder_path, \"metadata.json\"), 'w', encoding='utf-8') as f:\n",
    "            json.dump(metadata, f, ensure_ascii=False)\n",
    "        \n",
    "        print(\"Index sauvegardé avec succès !\")\n",
    "    \n",
    "    # -------------------------------------------------\n",
    "    def load_index(self, folder_path=\"../data/index_data\"):\n",
    "        print(f\"Chargement de l'index depuis {folder_path}...\")\n",
    "        idx_path = os.path.join(folder_path, \"inverted_index.json\")\n",
    "        meta_path = os.path.join(folder_path, \"metadata.json\")\n",
    "        \n",
    "        with open(idx_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        self.inverted_index = defaultdict(lambda: defaultdict(list))\n",
    "        for field, terms in data.items():\n",
    "            for term, postings in terms.items():\n",
    "                self.inverted_index[field][term] = [(int(d), int(f)) for d, f in postings]\n",
    "        \n",
    "        with open(meta_path, 'r', encoding='utf-8') as f:\n",
    "            meta = json.load(f)\n",
    "        \n",
    "        self.N = meta['N']\n",
    "        self.doc_lengths = {f: {int(k): v for k, v in d.items()} for f, d in meta['doc_lengths'].items()}\n",
    "        self.avg_doc_length = meta['avg_doc_length']\n",
    "        self.directors_set = set(meta['directors_set'])\n",
    "        self.genres_set = set(meta['genres_set'])\n",
    "        self.title_words = set(meta['title_words'])\n",
    "        self.years_set = set(meta['years_set'])\n",
    "        self.fields = meta['fields']\n",
    "        print(\"Index chargé !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 fichiers JSON trouvés. Chargement en cours...\n",
      "Chargement terminé : 50 films chargés\n",
      "\n",
      "Dataset chargé : 50 films\n",
      "Colonnes : ['Title', 'Overview', 'Tagline', 'Homepage', 'Release_Date', 'Vote_Average', 'Runtime', 'Poster_Path', 'Genres', 'Keywords', 'Director', 'budget', 'revenue', 'production_companies', 'Cast', 'clean_text']\n"
     ]
    }
   ],
   "source": [
    "# ============ UTILISATION AVEC VRAIES DONNÉES ============\n",
    "# Chemin vers ton dossier contenant les .json (un film par fichier)\n",
    "JSON_FOLDER = \"../data/docs/\"   # Change ici si besoin\n",
    "\n",
    "df = load_movies_from_json_folder(JSON_FOLDER)\n",
    "\n",
    "print(f\"\\nDataset chargé : {len(df)} films\")\n",
    "print(\"Colonnes :\", df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement du modèle spaCy...\n",
      "Construction de l'index inversé...\n",
      "Index construit : 50 documents\n",
      "Construction des dictionnaires de reconnaissance...\n",
      "Sauvegarde de l'index dans ../data/index...\n",
      "Index sauvegardé avec succès !\n"
     ]
    }
   ],
   "source": [
    "# Créer le moteur de recherche\n",
    "engine = SmartSearchEngine(df)\n",
    "engine.save_index(\"../data/index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Classification ===\n",
      "Director: ['christopher', 'nolan']\n",
      "Genre   : ['action']\n",
      "Year    : ['2010']\n",
      "General : ['movie']\n",
      "                                           Title           Director  \\\n",
      "0                                      Inception  Christopher Nolan   \n",
      "1                                  Batman Begins  Christopher Nolan   \n",
      "2                                The Dark Knight  Christopher Nolan   \n",
      "3                          The Dark Knight Rises  Christopher Nolan   \n",
      "4                                   Interstellar  Christopher Nolan   \n",
      "5                                     Iron Man 2        Jon Favreau   \n",
      "6                           Inglourious Basterds  Quentin Tarantino   \n",
      "7                                 Shutter Island    Martin Scorsese   \n",
      "8  The Lord of the Rings: The Return of the King      Peter Jackson   \n",
      "9                                     The Matrix    Lilly Wachowski   \n",
      "\n",
      "                               Genres Release_Date     score  \n",
      "0  Action, Science Fiction, Adventure   2010-07-15  7.745325  \n",
      "1                Action, Crime, Drama   2005-06-10  5.151345  \n",
      "2      Drama, Action, Crime, Thriller   2008-07-16  5.066263  \n",
      "3      Action, Crime, Drama, Thriller   2012-07-17  5.066263  \n",
      "4   Adventure, Drama, Science Fiction   2014-11-05  4.474089  \n",
      "5  Adventure, Action, Science Fiction   2010-04-28  3.271236  \n",
      "6                Drama, Thriller, War   2009-08-19  3.170845  \n",
      "7            Drama, Thriller, Mystery   2010-02-14  2.679063  \n",
      "8          Adventure, Fantasy, Action   2003-12-01  0.677256  \n",
      "9             Action, Science Fiction   1999-03-30  0.677256  \n"
     ]
    }
   ],
   "source": [
    "# ============ TESTS ============\n",
    "results = engine.search(\"action movies of christopher nolan 2010\", top_n=10)\n",
    "print(results[['Title' , 'Director','Genres', 'Release_Date', 'score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "class SearchEngineEvaluator:\n",
    "    \"\"\"\n",
    "    Évaluateur robuste pour le SmartSearchEngine\n",
    "    Gère correctement les index (int ou object), seuils, et cas vides\n",
    "    \"\"\"\n",
    "    def __init__(self, search_engine, df):\n",
    "        self.engine = search_engine\n",
    "        self.df = df.reset_index()  \n",
    "    \n",
    "    def create_evaluation_dataset(self, test_queries):\n",
    "        all_results = []\n",
    "        \n",
    "        for query_info in test_queries:\n",
    "            query = query_info['query']\n",
    "            relevant_ids = set(query_info['relevant_docs'])\n",
    "            \n",
    "            # Recherche avec top_n assez grand pour capter tous les possibles pertinents\n",
    "            results = self.engine.search(query, top_n=10)\n",
    "            \n",
    "            if results.empty:\n",
    "                continue\n",
    "                \n",
    "            # Récupérer les vrais IDs des documents dans les résultats\n",
    "            result_ids = results.index.tolist()  # ces IDs correspondent à df.index\n",
    "            \n",
    "            for rank, doc_id in enumerate(result_ids):\n",
    "                is_relevant = 1 if doc_id in relevant_ids else 0\n",
    "                score = results.loc[results.index == doc_id, 'score'].iloc[0] if 'score' in results.columns else 0\n",
    "                \n",
    "                all_results.append({\n",
    "                    'query': query,\n",
    "                    'doc_id': doc_id,\n",
    "                    'rank': rank + 1,\n",
    "                    'score': score,\n",
    "                    'y_true': is_relevant\n",
    "                })\n",
    "        \n",
    "        return pd.DataFrame(all_results)\n",
    "    \n",
    "    def find_best_threshold(self, eval_df):\n",
    "        if eval_df.empty or len(eval_df['score'].unique()) < 2:\n",
    "            return 0.0\n",
    "            \n",
    "        scores = sorted(eval_df['score'].unique(), reverse=True)\n",
    "        thresholds = [0] + scores[:-1]  # tester juste en dessous de chaque score\n",
    "        \n",
    "        best_f1 = 0\n",
    "        best_thresh = 0\n",
    "        \n",
    "        for thresh in thresholds:\n",
    "            y_pred = (eval_df['score'] >= thresh).astype(int)\n",
    "            f1 = f1_score(eval_df['y_true'], y_pred, zero_division=0)\n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "                best_thresh = thresh\n",
    "                \n",
    "        return best_thresh\n",
    "    \n",
    "    def evaluate(self, test_queries, top_k=10):\n",
    "        eval_df = self.create_evaluation_dataset(test_queries)\n",
    "        \n",
    "        if eval_df.empty:\n",
    "            print(\"Aucun résultat retourné par le moteur → évaluation impossible\")\n",
    "            return {'precision@10': 0.0, 'recall@10': 0.0, 'f1@10': 0.0, 'mrr': 0.0, 'map': 0.0}\n",
    "        \n",
    "        # === Métriques classiques à top@10 (plus pertinent pour la recherche) ===\n",
    "        top_results = eval_df[eval_df['rank'] <= top_k].copy()\n",
    "        \n",
    "        precision_at_k = top_results['y_true'].mean() if len(top_results) > 0 else 0.0\n",
    "        recall_at_k = top_results['y_true'].sum() / max(1, eval_df['y_true'].sum())\n",
    "        \n",
    "        # MRR (Mean Reciprocal Rank)\n",
    "        mrr = 0.0\n",
    "        map_score = 0.0\n",
    "        num_queries_with_relevant = 0\n",
    "        \n",
    "        for query in eval_df['query'].unique():\n",
    "            q_df = eval_df[eval_df['query'] == query]\n",
    "            relevant_ranks = q_df[q_df['y_true'] == 1]['rank']\n",
    "            if len(relevant_ranks) > 0:\n",
    "                num_queries_with_relevant += 1\n",
    "                first_rank = relevant_ranks.min()\n",
    "                mrr += 1.0 / first_rank\n",
    "                \n",
    "                # AP pour cette requête\n",
    "                ap = 0.0\n",
    "                relevant_found = 0\n",
    "                for k in range(1, min(top_k, len(q_df)) + 1):\n",
    "                    if q_df.iloc[k-1]['y_true'] == 1:\n",
    "                        relevant_found += 1\n",
    "                        ap += relevant_found / k\n",
    "                if relevant_found > 0:\n",
    "                    ap /= relevant_found\n",
    "                map_score += ap\n",
    "        \n",
    "        mrr = mrr / max(1, num_queries_with_relevant)\n",
    "        map_score = map_score / max(1, num_queries_with_relevant)\n",
    "        \n",
    "        f1_at_k = 2 * precision_at_k * recall_at_k / max(1e-9, precision_at_k + recall_at_k)\n",
    "        \n",
    "        return {\n",
    "            f'precision@{top_k}': round(precision_at_k, 4),\n",
    "            f'recall@{top_k}'   : round(recall_at_k, 4),\n",
    "            f'f1@{top_k}'       : round(f1_at_k, 4),\n",
    "            'mrr'               : round(mrr, 4),\n",
    "            'map'               : round(map_score, 4),\n",
    "            'total_queries'     : len(test_queries),\n",
    "            'queries_with_results': eval_df['query'].nunique()\n",
    "        }\n",
    "\n",
    "\n",
    "# ============ FONCTION D'AIDE POUR TROUVER LES DOCS PERTINENTS ============\n",
    "def find_relevant_docs(df, **criteria):\n",
    "    df_reset = df.reset_index()\n",
    "    mask = pd.Series([True] * len(df_reset))\n",
    "    \n",
    "    if 'title' in criteria:\n",
    "        mask &= df_reset['Title'].str.contains(criteria['title'], case=False, na=False)\n",
    "    if 'director' in criteria:\n",
    "        mask &= df_reset['Director'].str.contains(criteria['director'], case=False, na=False)\n",
    "    if 'genre' in criteria:\n",
    "        mask &= df_reset['Genres'].str.contains(criteria['genre'], case=False, na=False)\n",
    "    if 'year' in criteria:\n",
    "        mask &= df_reset['Release_Date'].str.contains(str(criteria['year']), na=False)\n",
    "    if 'exact_title' in criteria:\n",
    "        mask &= df_reset['Title'].str.lower() == criteria['exact_title'].lower()\n",
    "    \n",
    "    return df_reset[mask]['id'].tolist()  # retourne les vrais IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Classification ===\n",
      "Director: ['christopher', 'nolan']\n",
      "Title   : ['interstellar']\n",
      "\n",
      "=== Classification ===\n",
      "Director: ['tarantino']\n",
      "Genre   : ['fiction']\n",
      "Title   : ['pulp']\n",
      "\n",
      "=== Classification ===\n",
      "Director: ['christopher', 'nolan']\n",
      "Genre   : ['action']\n",
      "Year    : ['2010']\n",
      "General : ['movie']\n",
      "\n",
      "=== Classification ===\n",
      "Genre   : ['adventure']\n",
      "General : ['spielberg', 'movie']\n",
      "\n",
      "=== Classification ===\n",
      "Year    : ['2019']\n",
      "General : ['horror', 'movie']\n",
      "\n",
      "=== Classification ===\n",
      "Genre   : ['animation']\n",
      "General : ['pixar']\n",
      "\n",
      "=== Classification ===\n",
      "Genre   : ['war']\n",
      "Title   : ['star']\n",
      "General : ['episode']\n",
      "\n",
      "=== Classification ===\n",
      "Title   : ['batman', 'dark', 'knight']\n",
      "\n",
      "=== Classification ===\n",
      "Director: ['scorsese']\n",
      "Genre   : ['crime']\n",
      "General : ['dicaprio']\n",
      "\n",
      "=== Classification ===\n",
      "Genre   : ['comedy']\n",
      "Year    : ['2008']\n",
      "General : ['romantic']\n",
      "\n",
      "======================================================================\n",
      "            RÉSULTATS D'ÉVALUATION DU MOTEUR DE RECHERCHE\n",
      "======================================================================\n",
      "precision@10        : 0.0164\n",
      "recall@10           : 1.0\n",
      "f1@10               : 0.0323\n",
      "mrr                 : 0.25\n",
      "map                 : 0.25\n",
      "total_queries       : 10\n",
      "queries_with_results: 10\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Après avoir chargé ton df et ton engine\n",
    "# df = load_movies_from_json_folder(...) ou pd.read_csv(...)\n",
    "# engine = SmartSearchEngine(df, load_from_file=...) ou construit\n",
    "\n",
    "test_queries = [\n",
    "    {'query': 'christopher nolan interstellar',           'relevant_docs': find_relevant_docs(df, director='nolan', title='interstellar')},\n",
    "    {'query': 'tarantino pulp fiction',                   'relevant_docs': find_relevant_docs(df, director='tarantino', title='pulp fiction')},\n",
    "    {'query': 'action movies christopher nolan 2010',     'relevant_docs': find_relevant_docs(df, director='nolan', year=2010)},\n",
    "    {'query': 'spielberg adventure movie',                'relevant_docs': find_relevant_docs(df, director='spielberg', genre='adventure')[:20]},\n",
    "    {'query': 'horror movies 2019',                       'relevant_docs': find_relevant_docs(df, genre='horror', year=2019)},\n",
    "    {'query': 'pixar animation',                          'relevant_docs': find_relevant_docs(df, genre='animation', title='pixar')[:15]},\n",
    "    {'query': 'star wars episode',                        'relevant_docs': find_relevant_docs(df, title='star wars')},\n",
    "    {'query': 'batman dark knight',                       'relevant_docs': find_relevant_docs(df, title='dark knight')},\n",
    "    {'query': 'scorsese dicaprio crime',                  'relevant_docs': find_relevant_docs(df, director='scorsese', genre='crime')},\n",
    "    {'query': 'romantic comedy 2008',                     'relevant_docs': find_relevant_docs(df, genre='comedy', year=2008)[:10]},\n",
    "]\n",
    "\n",
    "evaluator = SearchEngineEvaluator(engine, df)\n",
    "metrics = evaluator.evaluate(test_queries, top_k=10)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"            RÉSULTATS D'ÉVALUATION DU MOTEUR DE RECHERCHE\")\n",
    "print(\"=\"*70)\n",
    "for k, v in metrics.items():\n",
    "    print(f\"{k:20}: {v}\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
