{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import math\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import spacy\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour charger tous les JSON d’un dossier\n",
    "def load_movies_from_json_folder(folder_path):\n",
    "    json_pattern = os.path.join(folder_path, \"*.json\")\n",
    "    json_files = glob.glob(json_pattern)\n",
    "    \n",
    "    if not json_files:\n",
    "        raise ValueError(f\"Aucun fichier .json trouvé dans {folder_path}\")\n",
    "    \n",
    "    print(f\"{len(json_files)} fichiers JSON trouvés. Chargement en cours...\")\n",
    "    \n",
    "    records = []\n",
    "    for file_path in json_files:\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "            records.append(data)\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur avec {file_path} : {e}\")\n",
    "    \n",
    "    df = pd.DataFrame(records)\n",
    "    \n",
    "    # Colonnes obligatoires (on crée les manquantes vides)\n",
    "    required = ['Title', 'Director', 'Genres', 'Overview', 'Release_Date']\n",
    "    for col in required:\n",
    "        if col not in df.columns:\n",
    "            df[col] = \"\"\n",
    "    \n",
    "    # Créer un ID stable (très utile quand on recharge)\n",
    "    if 'id' not in df.columns:\n",
    "        df = df.reset_index(drop=True)\n",
    "        df['id'] = df.index\n",
    "    \n",
    "    df = df.set_index('id')\n",
    "    \n",
    "    print(f\"Chargement terminé : {len(df)} films chargés\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmartSearchEngine:\n",
    "    def __init__(self, df, load_from_file=None):\n",
    "        self.df = df.copy()\n",
    "        self.N = len(df)\n",
    "        \n",
    "        print(\"Chargement du modèle spaCy...\")\n",
    "        self.nlp = spacy.load(\"en_core_web_sm\")\n",
    "        \n",
    "        self.fields = ['Title', 'Director', 'Genres', 'Overview', 'Release_Date']\n",
    "        \n",
    "        if load_from_file:\n",
    "            self.load_index(load_from_file)\n",
    "        else:\n",
    "            self.inverted_index = defaultdict(lambda: defaultdict(list))\n",
    "            self.doc_lengths = {}\n",
    "            self.avg_doc_length = {}\n",
    "            self.directors_set = set()\n",
    "            self.genres_set = set()\n",
    "            self.title_words = set()\n",
    "            self.years_set = set()\n",
    "            \n",
    "            self.build_index()\n",
    "            self.build_recognition_dicts()\n",
    "    \n",
    "    # -------------------------------------------------\n",
    "    def preprocess_text(self, text, is_date=False):\n",
    "        if pd.isna(text):\n",
    "            return []\n",
    "        text = str(text).lower()\n",
    "        if is_date:\n",
    "            return re.findall(r'\\b(?:19|20)\\d{2}\\b', text)\n",
    "        doc = self.nlp(text)\n",
    "        return [token.lemma_ for token in doc\n",
    "                if not token.is_stop and not token.is_punct and not token.is_space\n",
    "                and len(token.lemma_) > 2 and token.is_alpha]\n",
    "    \n",
    "    # -------------------------------------------------\n",
    "    def build_index(self):\n",
    "        print(\"Construction de l'index inversé...\")\n",
    "        for field in self.fields:\n",
    "            self.doc_lengths[field] = {}\n",
    "            self.avg_doc_length[field] = 0\n",
    "        \n",
    "        for idx, row in self.df.iterrows():\n",
    "            for field in self.fields:\n",
    "                tokens = self.preprocess_text(row[field], is_date=(field == 'Release_Date'))\n",
    "                self.doc_lengths[field][idx] = len(tokens)\n",
    "                freqs = defaultdict(int)\n",
    "                for t in tokens:\n",
    "                    freqs[t] += 1\n",
    "                for term, freq in freqs.items():\n",
    "                    self.inverted_index[field][term].append((idx, freq))\n",
    "        \n",
    "        for field in self.fields:\n",
    "            lengths = self.doc_lengths[field].values()\n",
    "            if lengths:\n",
    "                self.avg_doc_length[field] = np.mean(list(lengths))\n",
    "        \n",
    "        print(f\"Index construit : {self.N} documents\")\n",
    "    \n",
    "    # -------------------------------------------------\n",
    "    def build_recognition_dicts(self):\n",
    "        print(\"Construction des dictionnaires de reconnaissance...\")\n",
    "        for director in self.df['Director'].dropna():\n",
    "            self.directors_set.update(self.preprocess_text(director))\n",
    "        for genres in self.df['Genres'].dropna():\n",
    "            for g in str(genres).split(','):\n",
    "                self.genres_set.update(self.preprocess_text(g.strip()))\n",
    "        for title in self.df['Title'].dropna():\n",
    "            self.title_words.update(self.preprocess_text(title))\n",
    "        for date in self.df['Release_Date'].dropna():\n",
    "            self.years_set.update(self.preprocess_text(date, is_date=True))\n",
    "    \n",
    "    # -------------------------------------------------\n",
    "    def classify_query_terms(self, query_tokens):\n",
    "        classified = {'director':[], 'genre':[], 'title':[], 'year':[], 'general':[]}\n",
    "        for term in query_tokens:\n",
    "            if re.match(r'^(?:19|20)\\d{2}$', term):\n",
    "                classified['year'].append(term)\n",
    "            elif term in self.directors_set:\n",
    "                classified['director'].append(term)\n",
    "            elif term in self.genres_set:\n",
    "                classified['genre'].append(term)\n",
    "            elif term in self.title_words:\n",
    "                classified['title'].append(term)\n",
    "            else:\n",
    "                classified['general'].append(term)\n",
    "        return classified\n",
    "    \n",
    "    # -------------------------------------------------\n",
    "    def bm25_score(self, term, doc_id, field, k1=1.5, b=0.75):\n",
    "        if term not in self.inverted_index[field]:\n",
    "            return 0.0\n",
    "        postings = self.inverted_index[field][term]\n",
    "        tf = next((f for d, f in postings if d == doc_id), 0)\n",
    "        if tf == 0:\n",
    "            return 0.0\n",
    "        dfreq = len(postings)\n",
    "        idf = math.log((self.N - dfreq + 0.5) / (dfreq + 0.5) + 1.0)\n",
    "        doc_len = self.doc_lengths[field].get(doc_id, 0)\n",
    "        avg_len = self.avg_doc_length.get(field, 1) or 1\n",
    "        norm = 1 - b + b * (doc_len / avg_len)\n",
    "        return idf * (tf * (k1 + 1)) / (tf + k1 * norm)\n",
    "    \n",
    "    # -------------------------------------------------\n",
    "    def search(self, query, top_n=10):\n",
    "        years = re.findall(r'\\b(?:19|20)\\d{2}\\b', query)\n",
    "        tokens = self.preprocess_text(query) + years\n",
    "        if not tokens:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        classified = self.classify_query_terms(tokens)\n",
    "        print(\"\\n=== Classification ===\")\n",
    "        for cat, terms in classified.items():\n",
    "            if terms: print(f\"{cat.capitalize():8}: {terms}\")\n",
    "        \n",
    "        candidates = set()\n",
    "        mapping = {\n",
    "            'director': ['Director'],\n",
    "            'genre':    ['Genres'],\n",
    "            'title':    ['Title'],\n",
    "            'year':     ['Release_Date'],\n",
    "            'general':  self.fields\n",
    "        }\n",
    "        for cat, terms in classified.items():\n",
    "            for term in terms:\n",
    "                for field in mapping[cat]:\n",
    "                    if term in self.inverted_index[field]:\n",
    "                        candidates.update(d for d, _ in self.inverted_index[field][term])\n",
    "        \n",
    "        scores = {}\n",
    "        for doc_id in candidates:\n",
    "            s = 0.0\n",
    "            for t in classified['director']: s += self.bm25_score(t, doc_id, 'Director')\n",
    "            for t in classified['genre']:    s += self.bm25_score(t, doc_id, 'Genres')\n",
    "            for t in classified['title']:    s += self.bm25_score(t, doc_id, 'Title')\n",
    "            for t in classified['year']:     s += self.bm25_score(t, doc_id, 'Release_Date')\n",
    "            for t in classified['general']:\n",
    "                for f in self.fields:\n",
    "                    s += self.bm25_score(t, doc_id, f)\n",
    "            if s > 0:\n",
    "                scores[doc_id] = s\n",
    "        \n",
    "        top = sorted(scores.items(), key=lambda x: x[1], reverse=True)[:top_n]\n",
    "        if not top:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        ids, sc = zip(*top)\n",
    "        res = self.df.loc[list(ids), ['Title','Overview','Genres','Director','Release_Date']].copy()\n",
    "        res['score'] = sc\n",
    "        return res.reset_index(drop=True)\n",
    "    \n",
    "    # -------------------------------------------------\n",
    "    def save_index(self, folder_path=\"../data/index_data\"):\n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "        print(f\"Sauvegarde de l'index dans {folder_path}...\")\n",
    "        \n",
    "        # Correction ici : on utilise bien \"terms\" et pas \"terms_dict\"\n",
    "        serializable_index = {}\n",
    "        for field, terms in self.inverted_index.items():\n",
    "            serializable_index[field] = {}\n",
    "            for term, postings in terms.items():\n",
    "                serializable_index[field][term] = [[int(d), int(f)] for d, f in postings]\n",
    "        \n",
    "        with open(os.path.join(folder_path, \"inverted_index.json\"), 'w', encoding='utf-8') as f:\n",
    "            json.dump(serializable_index, f, ensure_ascii=False)\n",
    "        \n",
    "        metadata = {\n",
    "            'N': self.N,\n",
    "            'doc_lengths': {f: {int(k): v for k, v in d.items()} for f, d in self.doc_lengths.items()},\n",
    "            'avg_doc_length': self.avg_doc_length,\n",
    "            'directors_set': list(self.directors_set),\n",
    "            'genres_set': list(self.genres_set),\n",
    "            'title_words': list(self.title_words),\n",
    "            'years_set': list(self.years_set),\n",
    "            'fields': self.fields\n",
    "        }\n",
    "        with open(os.path.join(folder_path, \"metadata.json\"), 'w', encoding='utf-8') as f:\n",
    "            json.dump(metadata, f, ensure_ascii=False)\n",
    "        \n",
    "        print(\"Index sauvegardé avec succès !\")\n",
    "    \n",
    "    # -------------------------------------------------\n",
    "    def load_index(self, folder_path=\"../data/index_data\"):\n",
    "        print(f\"Chargement de l'index depuis {folder_path}...\")\n",
    "        idx_path = os.path.join(folder_path, \"inverted_index.json\")\n",
    "        meta_path = os.path.join(folder_path, \"metadata.json\")\n",
    "        \n",
    "        with open(idx_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        self.inverted_index = defaultdict(lambda: defaultdict(list))\n",
    "        for field, terms in data.items():\n",
    "            for term, postings in terms.items():\n",
    "                self.inverted_index[field][term] = [(int(d), int(f)) for d, f in postings]\n",
    "        \n",
    "        with open(meta_path, 'r', encoding='utf-8') as f:\n",
    "            meta = json.load(f)\n",
    "        \n",
    "        self.N = meta['N']\n",
    "        self.doc_lengths = {f: {int(k): v for k, v in d.items()} for f, d in meta['doc_lengths'].items()}\n",
    "        self.avg_doc_length = meta['avg_doc_length']\n",
    "        self.directors_set = set(meta['directors_set'])\n",
    "        self.genres_set = set(meta['genres_set'])\n",
    "        self.title_words = set(meta['title_words'])\n",
    "        self.years_set = set(meta['years_set'])\n",
    "        self.fields = meta['fields']\n",
    "        print(\"Index chargé !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 fichiers JSON trouvés. Chargement en cours...\n",
      "Chargement terminé : 50 films chargés\n",
      "\n",
      "Dataset chargé : 50 films\n",
      "Colonnes : ['Title', 'Overview', 'Tagline', 'Homepage', 'Release_Date', 'Vote_Average', 'Runtime', 'Poster_Path', 'Genres', 'Keywords', 'Director', 'budget', 'revenue', 'production_companies', 'Cast', 'clean_text']\n"
     ]
    }
   ],
   "source": [
    "# ============ UTILISATION AVEC VRAIES DONNÉES ============\n",
    "# Chemin vers ton dossier contenant les .json (un film par fichier)\n",
    "JSON_FOLDER = \"../data/docs/\"   # Change ici si besoin\n",
    "\n",
    "df = load_movies_from_json_folder(JSON_FOLDER)\n",
    "\n",
    "print(f\"\\nDataset chargé : {len(df)} films\")\n",
    "print(\"Colonnes :\", df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement du modèle spaCy...\n",
      "Construction de l'index inversé...\n",
      "Index construit : 50 documents\n",
      "Construction des dictionnaires de reconnaissance...\n",
      "Sauvegarde de l'index dans ../data/index...\n",
      "Index sauvegardé avec succès !\n"
     ]
    }
   ],
   "source": [
    "# Créer le moteur de recherche\n",
    "engine = SmartSearchEngine(df)\n",
    "engine.save_index(\"../data/index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Classification ===\n",
      "Director: ['christopher', 'nolan']\n",
      "Genre   : ['action']\n",
      "Year    : ['2010']\n",
      "General : ['movie']\n",
      "                                           Title           Director  \\\n",
      "0                                      Inception  Christopher Nolan   \n",
      "1                                  Batman Begins  Christopher Nolan   \n",
      "2                                The Dark Knight  Christopher Nolan   \n",
      "3                          The Dark Knight Rises  Christopher Nolan   \n",
      "4                                   Interstellar  Christopher Nolan   \n",
      "5                                     Iron Man 2        Jon Favreau   \n",
      "6                           Inglourious Basterds  Quentin Tarantino   \n",
      "7                                 Shutter Island    Martin Scorsese   \n",
      "8  The Lord of the Rings: The Return of the King      Peter Jackson   \n",
      "9                                     The Matrix    Lilly Wachowski   \n",
      "\n",
      "                               Genres Release_Date     score  \n",
      "0  Action, Science Fiction, Adventure   2010-07-15  7.745325  \n",
      "1                Action, Crime, Drama   2005-06-10  5.151345  \n",
      "2      Drama, Action, Crime, Thriller   2008-07-16  5.066263  \n",
      "3      Action, Crime, Drama, Thriller   2012-07-17  5.066263  \n",
      "4   Adventure, Drama, Science Fiction   2014-11-05  4.474089  \n",
      "5  Adventure, Action, Science Fiction   2010-04-28  3.271236  \n",
      "6                Drama, Thriller, War   2009-08-19  3.170845  \n",
      "7            Drama, Thriller, Mystery   2010-02-14  2.679063  \n",
      "8          Adventure, Fantasy, Action   2003-12-01  0.677256  \n",
      "9             Action, Science Fiction   1999-03-30  0.677256  \n"
     ]
    }
   ],
   "source": [
    "# ============ TESTS ============\n",
    "results = engine.search(\"action movies of christopher nolan 2010\", top_n=10)\n",
    "print(results[['Title' , 'Director','Genres', 'Release_Date', 'score']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
